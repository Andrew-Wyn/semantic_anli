{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.conda/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: polars in ./.conda/lib/python3.11/site-packages (0.20.31)\n",
      "Requirement already satisfied: transformers in ./.conda/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.11/site-packages (4.66.4)\n",
      "Requirement already satisfied: rich in ./.conda/lib/python3.11/site-packages (13.7.1)\n",
      "Requirement already satisfied: sentencepiece in ./.conda/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: protobuf in ./.conda/lib/python3.11/site-packages (5.27.1)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.11/site-packages (from torch) (3.15.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.conda/lib/python3.11/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.conda/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in ./.conda/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/lib/python3.11/site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/lib/python3.11/site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.11/site-packages (from rich) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./.conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch polars transformers tqdm rich sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Total samples 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gioffre/projects/semantic_anli/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gioffre/projects/semantic_anli/.conda/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cid',\n",
       " 'premise',\n",
       " 'hypothesis',\n",
       " 'label',\n",
       " 'Generated ENTAILMENT Hypothesis',\n",
       " 'ENTAILMENT Correct?',\n",
       " 'ENTAILMENT Adversarial?',\n",
       " 'Generated NEUTRAL Hypothesis',\n",
       " 'NEUTRAL Correct?',\n",
       " 'NEUTRAL Adversarial',\n",
       " 'Generated CONTRADICTION Hypothesis',\n",
       " 'CONTRADICTION Correct?',\n",
       " 'CONTRADICTION Adversarial']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "LABEL_NAMES = [\"ENTAILMENT\", \"NEUTRAL\", \"CONTRADICTION\"]\n",
    "input_file = \"data/GPT-4o_raw_single_class_prompt.csv\"\n",
    "df = pl.read_csv(input_file)\n",
    "print(\"Total samples\", df.height)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the scores\n",
    "Check whether the samples generated by LLama3 that are *correct* (i.e., checked by a human), are also *difficult* for the model (i.e., the model fails to classify them correctly).\n",
    "\n",
    "This section only writes on another `.csv` file the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> loading MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "> loading MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\n",
      "> loading Joelzhang/deberta-v3-large-snli_mnli_fever_anli_R1_R2_R3-nli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gioffre/projects/semantic_anli/.conda/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODELS = {}\n",
    "TOKENIZERS = {}\n",
    "\n",
    "model_name_base = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "model_name_large = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "model_name_large_2 = \"Joelzhang/deberta-v3-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "MAP = {\n",
    "    'base' : model_name_base,\n",
    "    'large1': model_name_large,\n",
    "    'large2': model_name_large_2,\n",
    "}\n",
    "\n",
    "for model_name in MAP.values():\n",
    "    print(f\"> loading {model_name}\")\n",
    "    TOKENIZERS[model_name] = AutoTokenizer.from_pretrained(model_name, cache_dir='./.hf_cache')\n",
    "    MODELS[model_name] = AutoModelForSequenceClassification.from_pretrained(model_name, cache_dir='./.hf_cache').to(device)\n",
    "\n",
    "\n",
    "def inference(model_name, premise, hypothesis):\n",
    "    model_input = TOKENIZERS[model_name](premise, hypothesis, truncation=False, return_tensors=\"pt\")\n",
    "    output = MODELS[model_name](model_input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    return {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, LABEL_NAMES)}\n",
    "\n",
    "def predict(model_name, premise, hypothesis, label):\n",
    "    prediction = inference(model_name, premise, hypothesis)\n",
    "    predicted = max(prediction, key=prediction.get)\n",
    "    return int(predicted != label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "> model base: 100%|██████████| 29/29 [00:02<00:00, 10.43it/s]\n",
      "> model large1: 100%|██████████| 29/29 [00:08<00:00,  3.47it/s]\n",
      "> model large2: 100%|██████████| 29/29 [00:08<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "res = {}\n",
    "for label in LABEL_NAMES:\n",
    "    for model_id in MAP.keys():\n",
    "        res[f\"new {label} hypothesis fools {model_id.upper()}\"] = []\n",
    "#pprint(res)\n",
    "\n",
    "for model_id, model_name in MAP.items():\n",
    "    for i, elem in tqdm(enumerate(df.iter_rows(named=True)), desc=f'> model {model_id}', total=df.height):\n",
    "        for label in LABEL_NAMES:\n",
    "            # filters empty cells\n",
    "            if elem[f'Generated {label} Hypothesis'] == '':\n",
    "                continue\n",
    "            if elem[f'{label} Correct?'] == True:\n",
    "                int_flag = predict(model_name, elem['premise'], elem['hypothesis'], elem['label'])\n",
    "                res[f'new {label} hypothesis fools {model_id.upper()}'].append(int_flag)\n",
    "            else:\n",
    "                res[f'new {label} hypothesis fools {model_id.upper()}'].append(None)\n",
    "#pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new ENTAILMENT hypothesis fools BASE': [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'new ENTAILMENT hypothesis fools LARGE1': [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'new ENTAILMENT hypothesis fools LARGE2': [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'new NEUTRAL hypothesis fools BASE': [None, None, None, None, None, None, None, None, None, None, 1, 0, 0, 0, 0, 0, 1, 0, 0, None, None, None, None, None, None, None, None, None, None], 'new NEUTRAL hypothesis fools LARGE1': [None, None, None, None, None, None, None, None, None, None, 1, 0, 0, 0, 0, 0, 1, 0, 0, None, None, None, None, None, None, None, None, None, None], 'new NEUTRAL hypothesis fools LARGE2': [None, None, None, None, None, None, None, None, None, None, 1, 0, 0, 0, 0, 0, 1, 0, 0, None, None, None, None, None, None, None, None, None, None], 'new CONTRADICTION hypothesis fools BASE': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0], 'new CONTRADICTION hypothesis fools LARGE1': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'new CONTRADICTION hypothesis fools LARGE2': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 22)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cid</th><th>premise</th><th>hypothesis</th><th>label</th><th>Generated ENTAILMENT Hypothesis</th><th>ENTAILMENT Correct?</th><th>ENTAILMENT Adversarial?</th><th>Generated NEUTRAL Hypothesis</th><th>NEUTRAL Correct?</th><th>NEUTRAL Adversarial</th><th>Generated CONTRADICTION Hypothesis</th><th>CONTRADICTION Correct?</th><th>CONTRADICTION Adversarial</th><th>new ENTAILMENT hypothesis fools BASE</th><th>new ENTAILMENT hypothesis fools LARGE1</th><th>new ENTAILMENT hypothesis fools LARGE2</th><th>new NEUTRAL hypothesis fools BASE</th><th>new NEUTRAL hypothesis fools LARGE1</th><th>new NEUTRAL hypothesis fools LARGE2</th><th>new CONTRADICTION hypothesis fools BASE</th><th>new CONTRADICTION hypothesis fools LARGE1</th><th>new CONTRADICTION hypothesis fools LARGE2</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>184052</td><td>&quot;Gangs of New York . The screen…</td><td>&quot;Kenneth Lonergan is a writer o…</td><td>&quot;ENTAILMENT&quot;</td><td>&quot;Hypothesis: Kenneth Lonergan, …</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>217178</td><td>&quot;Pakistan Movement . The Pakist…</td><td>&quot;The Pakistan Movement was the …</td><td>&quot;NEUTRAL&quot;</td><td>&quot;The series of social, politica…</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>169984</td><td>&quot;The Brat Pack is a nickname gi…</td><td>&quot;The Brat Pack is a nickname gi…</td><td>&quot;CONTRADICTION&quot;</td><td>&quot;In the 1980s, a group of young…</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>1</td><td>1</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>120315</td><td>&quot;Bret Easton Ellis . Ellis also…</td><td>&quot;Bret Easton Ellis barely wrote…</td><td>&quot;CONTRADICTION&quot;</td><td>&quot;Bret Easton Ellis, who penned …</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>1</td><td>1</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>145735</td><td>&quot;New York Knicks . The Knicks c…</td><td>&quot;The New York Knicks are in the…</td><td>&quot;ENTAILMENT&quot;</td><td>&quot;Competing in the National Bask…</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 22)\n",
       "┌────────┬────────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ cid    ┆ premise    ┆ hypothesis ┆ label     ┆ … ┆ new       ┆ new CONTR ┆ new CONTR ┆ new CONTR │\n",
       "│ ---    ┆ ---        ┆ ---        ┆ ---       ┆   ┆ NEUTRAL   ┆ ADICTION  ┆ ADICTION  ┆ ADICTION  │\n",
       "│ i64    ┆ str        ┆ str        ┆ str       ┆   ┆ hypothesi ┆ hypothesi ┆ hypothesi ┆ hypothesi │\n",
       "│        ┆            ┆            ┆           ┆   ┆ s fools   ┆ s f…      ┆ s f…      ┆ s f…      │\n",
       "│        ┆            ┆            ┆           ┆   ┆ L…        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│        ┆            ┆            ┆           ┆   ┆ ---       ┆ i64       ┆ i64       ┆ i64       │\n",
       "│        ┆            ┆            ┆           ┆   ┆ i64       ┆           ┆           ┆           │\n",
       "╞════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 184052 ┆ Gangs of   ┆ Kenneth    ┆ ENTAILMEN ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│        ┆ New York . ┆ Lonergan   ┆ T         ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ The        ┆ is a       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ screen…    ┆ writer o…  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 217178 ┆ Pakistan   ┆ The        ┆ NEUTRAL   ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│        ┆ Movement . ┆ Pakistan   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ The        ┆ Movement   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ Pakist…    ┆ was the …  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 169984 ┆ The Brat   ┆ The Brat   ┆ CONTRADIC ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│        ┆ Pack is a  ┆ Pack is a  ┆ TION      ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ nickname   ┆ nickname   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ gi…        ┆ gi…        ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 120315 ┆ Bret       ┆ Bret       ┆ CONTRADIC ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│        ┆ Easton     ┆ Easton     ┆ TION      ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ Ellis .    ┆ Ellis      ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ Ellis      ┆ barely     ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ also…      ┆ wrote…     ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 145735 ┆ New York   ┆ The New    ┆ ENTAILMEN ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│        ┆ Knicks .   ┆ York       ┆ T         ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ The Knicks ┆ Knicks are ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ c…         ┆ in the…    ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────┴────────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label in LABEL_NAMES:\n",
    "    for model_id in MAP.keys():\n",
    "        df = df.with_columns(\n",
    "            pl.Series(\n",
    "                name=f\"new {label} hypothesis fools {model_id.upper()}\", \n",
    "                values=res[f\"new {label} hypothesis fools {model_id.upper()}\"]\n",
    "            ),\n",
    "        )\n",
    "df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 25)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cid</th><th>premise</th><th>hypothesis</th><th>label</th><th>Generated ENTAILMENT Hypothesis</th><th>ENTAILMENT Correct?</th><th>ENTAILMENT Adversarial?</th><th>Generated NEUTRAL Hypothesis</th><th>NEUTRAL Correct?</th><th>NEUTRAL Adversarial</th><th>Generated CONTRADICTION Hypothesis</th><th>CONTRADICTION Correct?</th><th>CONTRADICTION Adversarial</th><th>new ENTAILMENT hypothesis fools BASE</th><th>new ENTAILMENT hypothesis fools LARGE1</th><th>new ENTAILMENT hypothesis fools LARGE2</th><th>new NEUTRAL hypothesis fools BASE</th><th>new NEUTRAL hypothesis fools LARGE1</th><th>new NEUTRAL hypothesis fools LARGE2</th><th>new CONTRADICTION hypothesis fools BASE</th><th>new CONTRADICTION hypothesis fools LARGE1</th><th>new CONTRADICTION hypothesis fools LARGE2</th><th>ENTAILMENT difficulty score</th><th>NEUTRAL difficulty score</th><th>CONTRADICTION difficulty score</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>184052</td><td>&quot;Gangs of New York . The screen…</td><td>&quot;Kenneth Lonergan is a writer o…</td><td>&quot;ENTAILMENT&quot;</td><td>&quot;Hypothesis: Kenneth Lonergan, …</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>null</td><td>null</td></tr><tr><td>217178</td><td>&quot;Pakistan Movement . The Pakist…</td><td>&quot;The Pakistan Movement was the …</td><td>&quot;NEUTRAL&quot;</td><td>&quot;The series of social, politica…</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>null</td><td>null</td></tr><tr><td>169984</td><td>&quot;The Brat Pack is a nickname gi…</td><td>&quot;The Brat Pack is a nickname gi…</td><td>&quot;CONTRADICTION&quot;</td><td>&quot;In the 1980s, a group of young…</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>1</td><td>1</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3</td><td>null</td><td>null</td></tr><tr><td>120315</td><td>&quot;Bret Easton Ellis . Ellis also…</td><td>&quot;Bret Easton Ellis barely wrote…</td><td>&quot;CONTRADICTION&quot;</td><td>&quot;Bret Easton Ellis, who penned …</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>1</td><td>1</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3</td><td>null</td><td>null</td></tr><tr><td>145735</td><td>&quot;New York Knicks . The Knicks c…</td><td>&quot;The New York Knicks are in the…</td><td>&quot;ENTAILMENT&quot;</td><td>&quot;Competing in the National Bask…</td><td>true</td><td>false</td><td>null</td><td>false</td><td>false</td><td>null</td><td>false</td><td>false</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 25)\n",
       "┌────────┬────────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ cid    ┆ premise    ┆ hypothesis ┆ label     ┆ … ┆ new CONTR ┆ ENTAILMEN ┆ NEUTRAL   ┆ CONTRADIC │\n",
       "│ ---    ┆ ---        ┆ ---        ┆ ---       ┆   ┆ ADICTION  ┆ T difficu ┆ difficult ┆ TION diff │\n",
       "│ i64    ┆ str        ┆ str        ┆ str       ┆   ┆ hypothesi ┆ lty score ┆ y score   ┆ iculty    │\n",
       "│        ┆            ┆            ┆           ┆   ┆ s f…      ┆ ---       ┆ ---       ┆ score     │\n",
       "│        ┆            ┆            ┆           ┆   ┆ ---       ┆ i64       ┆ i64       ┆ ---       │\n",
       "│        ┆            ┆            ┆           ┆   ┆ i64       ┆           ┆           ┆ i64       │\n",
       "╞════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 184052 ┆ Gangs of   ┆ Kenneth    ┆ ENTAILMEN ┆ … ┆ null      ┆ 0         ┆ null      ┆ null      │\n",
       "│        ┆ New York . ┆ Lonergan   ┆ T         ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ The        ┆ is a       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ screen…    ┆ writer o…  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 217178 ┆ Pakistan   ┆ The        ┆ NEUTRAL   ┆ … ┆ null      ┆ 0         ┆ null      ┆ null      │\n",
       "│        ┆ Movement . ┆ Pakistan   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ The        ┆ Movement   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ Pakist…    ┆ was the …  ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 169984 ┆ The Brat   ┆ The Brat   ┆ CONTRADIC ┆ … ┆ null      ┆ 3         ┆ null      ┆ null      │\n",
       "│        ┆ Pack is a  ┆ Pack is a  ┆ TION      ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ nickname   ┆ nickname   ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ gi…        ┆ gi…        ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 120315 ┆ Bret       ┆ Bret       ┆ CONTRADIC ┆ … ┆ null      ┆ 3         ┆ null      ┆ null      │\n",
       "│        ┆ Easton     ┆ Easton     ┆ TION      ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ Ellis .    ┆ Ellis      ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ Ellis      ┆ barely     ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ also…      ┆ wrote…     ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 145735 ┆ New York   ┆ The New    ┆ ENTAILMEN ┆ … ┆ null      ┆ 0         ┆ null      ┆ null      │\n",
       "│        ┆ Knicks .   ┆ York       ┆ T         ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ The Knicks ┆ Knicks are ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│        ┆ c…         ┆ in the…    ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────┴────────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.with_columns(\n",
    "    (\n",
    "        pl.col(\"new ENTAILMENT hypothesis fools BASE\")   +  \n",
    "        pl.col(\"new ENTAILMENT hypothesis fools LARGE1\") + \n",
    "        pl.col(\"new ENTAILMENT hypothesis fools LARGE2\")\n",
    "    ).alias(\"ENTAILMENT difficulty score\"),\n",
    "    (\n",
    "        pl.col(\"new NEUTRAL hypothesis fools BASE\")   +  \n",
    "        pl.col(\"new NEUTRAL hypothesis fools LARGE1\") + \n",
    "        pl.col(\"new NEUTRAL hypothesis fools LARGE2\")\n",
    "    ).alias(\"NEUTRAL difficulty score\"),\n",
    "    (\n",
    "        pl.col(\"new CONTRADICTION hypothesis fools BASE\")   +  \n",
    "        pl.col(\"new CONTRADICTION hypothesis fools LARGE1\") + \n",
    "        pl.col(\"new CONTRADICTION hypothesis fools LARGE2\")\n",
    "    ).alias(\"CONTRADICTION difficulty score\"),\n",
    ")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Written stats csv.\n"
     ]
    }
   ],
   "source": [
    "new_df.write_csv(input_file.replace('.csv', '_STATS.csv'))\n",
    "print(\"> Written stats csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "I want to see:\n",
    "- how many generated examples are correct for each category\n",
    "- how many correct examples are can fool 0, 1, 2, 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "console = Console()\n",
    "\n",
    "new_df = pl.read_csv(input_file.replace('.csv', '_STATS.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">               data/GPT-4o_raw_single_class_prompt_STATS.csv               </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Category                                          </span>┃<span style=\"font-weight: bold\"> Percentage </span>┃<span style=\"font-weight: bold\"> Values </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Synthetic ENTAILMENT    samples that are correct: </span>│<span style=\"color: #008000; text-decoration-color: #008000\">  100.00%   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  10/10 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Synthetic NEUTRAL       samples that are correct: </span>│<span style=\"color: #008000; text-decoration-color: #008000\">  100.00%   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    9/9 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Synthetic CONTRADICTION samples that are correct: </span>│<span style=\"color: #008000; text-decoration-color: #008000\">  100.00%   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  10/10 </span>│\n",
       "└───────────────────────────────────────────────────┴────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m               data/GPT-4o_raw_single_class_prompt_STATS.csv               \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mCategory                                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPercentage\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValues\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mSynthetic ENTAILMENT    samples that are correct:\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m 100.00%  \u001b[0m\u001b[32m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 10/10\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSynthetic NEUTRAL       samples that are correct:\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m 100.00%  \u001b[0m\u001b[32m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   9/9\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSynthetic CONTRADICTION samples that are correct:\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m 100.00%  \u001b[0m\u001b[32m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 10/10\u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────────────────────────────┴────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(title=input_file.replace('.csv', '_STATS.csv'))\n",
    "\n",
    "table.add_column(\"Category\", justify=\"left\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Percentage\", style=\"green\", justify='center')\n",
    "table.add_column(\"Values\", justify=\"right\", style=\"magenta\")\n",
    "\n",
    "for label in LABEL_NAMES:\n",
    "    num_correct = new_df.filter(pl.col(f'{label} Correct?') == True).height\n",
    "    support = new_df.filter(pl.col(f'Generated {label} Hypothesis') != '')\n",
    "    table.add_row(\n",
    "        f\"Synthetic {label:<13} samples that are correct:\", \n",
    "        f\"{100*num_correct/support.height:.2f}%\", \n",
    "        f\"{num_correct}/{support.height}\") \n",
    "\n",
    "console.print(table)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                   data/GPT-4o_raw_single_class_prompt_STATS.csv                                   </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Category of </span>┃<span style=\"font-weight: bold\">             </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">             </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">         </span>┃\n",
       "┃<span style=\"font-weight: bold\"> correct     </span>┃<span style=\"font-weight: bold\">             </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">             </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">         </span>┃\n",
       "┃<span style=\"font-weight: bold\"> synthetic   </span>┃<span style=\"font-weight: bold\">   Fool 0    </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> Fool &gt;= 1  </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">  Fool &gt;= 2  </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> Fool &gt;= 3  </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\">         </span>┃\n",
       "┃<span style=\"font-weight: bold\"> samples     </span>┃<span style=\"font-weight: bold\">   models    </span>┃<span style=\"font-weight: bold\">   %    </span>┃<span style=\"font-weight: bold\">   models   </span>┃<span style=\"font-weight: bold\">   %    </span>┃<span style=\"font-weight: bold\">   models    </span>┃<span style=\"font-weight: bold\">   %    </span>┃<span style=\"font-weight: bold\">   models   </span>┃<span style=\"font-weight: bold\">   %    </span>┃<span style=\"font-weight: bold\"> Support </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ENTAILMENT  </span>│<span style=\"color: #800000; text-decoration-color: #800000\">      7      </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 70.00% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      3     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 30.00% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      3      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 30.00% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      3     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 30.00% </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      10 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> NEUTRAL     </span>│<span style=\"color: #800000; text-decoration-color: #800000\">      7      </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 77.78% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      2     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 22.22% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      2      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 22.22% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      2     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 22.22% </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       9 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CONTRADICT… </span>│<span style=\"color: #800000; text-decoration-color: #800000\">      7      </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 70.00% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      3     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 30.00% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      2      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 20.00% </span>│<span style=\"color: #008000; text-decoration-color: #008000\">      1     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 10.00% </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      10 </span>│\n",
       "└─────────────┴─────────────┴────────┴────────────┴────────┴─────────────┴────────┴────────────┴────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                   data/GPT-4o_raw_single_class_prompt_STATS.csv                                   \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mCategory of\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m             \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m             \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m         \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1mcorrect    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m             \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m             \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m         \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1msynthetic  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Fool 0   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFool >= 1 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Fool >= 2 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFool >= 3 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m         \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1msamples    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  models   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  models  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  models   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  models  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSupport\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mENTAILMENT \u001b[0m\u001b[36m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m     7     \u001b[0m\u001b[31m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m70.00%\u001b[0m\u001b[31m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     3    \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m30.00%\u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     3     \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m30.00%\u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     3    \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m30.00%\u001b[0m\u001b[32m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     10\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mNEUTRAL    \u001b[0m\u001b[36m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m     7     \u001b[0m\u001b[31m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m77.78%\u001b[0m\u001b[31m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     2    \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m22.22%\u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     2     \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m22.22%\u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     2    \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m22.22%\u001b[0m\u001b[32m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      9\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCONTRADICT…\u001b[0m\u001b[36m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m     7     \u001b[0m\u001b[31m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m70.00%\u001b[0m\u001b[31m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     3    \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m30.00%\u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     2     \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m20.00%\u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m     1    \u001b[0m\u001b[32m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m10.00%\u001b[0m\u001b[32m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     10\u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────┴─────────────┴────────┴────────────┴────────┴─────────────┴────────┴────────────┴────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(title=input_file.replace('.csv', '_STATS.csv'))\n",
    "\n",
    "table.add_column(\"Category of correct synthetic samples\", justify=\"left\", style=\"cyan\", no_wrap=False)\n",
    "table.add_column(\"Fool 0 models\", style=\"red\", justify='center')\n",
    "table.add_column(\"%\", style=\"red\", justify='center')\n",
    "table.add_column(\"Fool >= 1 models\", style=\"green\", justify='center')\n",
    "table.add_column(\"%\", style=\"green\", justify='center')\n",
    "table.add_column(\"Fool >= 2 models\", style=\"green\", justify='center')\n",
    "table.add_column(\"%\", style=\"green\", justify='center')\n",
    "table.add_column(\"Fool >= 3 models\", style=\"green\", justify='center')\n",
    "table.add_column(\"%\", style=\"green\", justify='center')\n",
    "table.add_column(\"Support\", justify=\"right\", style=\"magenta\")\n",
    "\n",
    "for label in LABEL_NAMES:\n",
    "    # retrieve correct samples per label\n",
    "    correct_df = new_df.filter(pl.col(f'{label} Correct?') == True)\n",
    "    num_correct = correct_df.height\n",
    "\n",
    "    fool_0 = correct_df.filter(pl.col(f\"{label} difficulty score\") == 0).height\n",
    "    fool_at_least_1 = correct_df.filter(pl.col(f\"{label} difficulty score\") >= 1).height\n",
    "    fool_at_least_2 = correct_df.filter(pl.col(f\"{label} difficulty score\") >= 2).height\n",
    "    fool_at_least_3 = correct_df.filter(pl.col(f\"{label} difficulty score\") >= 3).height\n",
    "\n",
    "    table.add_row(\n",
    "        label, \n",
    "        f\"{fool_0:>2}\",\n",
    "        f\"{100*fool_0/num_correct:.2f}%\", \n",
    "        f\"{fool_at_least_1:>2}\",\n",
    "        f\"{100*fool_at_least_1/num_correct:.2f}%\", \n",
    "        f\"{fool_at_least_2:>2}\",\n",
    "        f\"{100*fool_at_least_2/num_correct:.2f}%\", \n",
    "        f\"{fool_at_least_3:>2}\",\n",
    "        f\"{100*fool_at_least_3/num_correct:.2f}%\", \n",
    "        f\"{num_correct}\"\n",
    ") \n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export a csv containing only adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_df = {\n",
    "    \"cid\" : [],\n",
    "    \"premise\": [],\n",
    "    \"original hypothesis\": [],\n",
    "    \"original label\": [],\n",
    "    \"generated hypothesis\": [],\n",
    "    \"prompted label\": [],\n",
    "    \"models fooled\": [],\n",
    "}\n",
    "\n",
    "for label in LABEL_NAMES:\n",
    "    # retrieve correct samples per label\n",
    "    correct_df = new_df.filter(pl.col(f'{label} Correct?') == True)\n",
    "    num_correct = correct_df.height\n",
    "\n",
    "    adversarial_samples = correct_df.filter(pl.col(f\"{label} difficulty score\") >= 1)\n",
    "    for row in adversarial_samples.iter_rows(named=True):\n",
    "        to_df['cid'].append(row['cid'])\n",
    "        to_df['premise'].append(row['premise'])\n",
    "        to_df[\"original hypothesis\"].append(row['hypothesis'])\n",
    "        to_df[\"original label\"].append(row['label'])\n",
    "        to_df[\"generated hypothesis\"].append(row[f'Generated {label} Hypothesis'])\n",
    "        to_df[\"prompted label\"].append(label)\n",
    "        to_df[\"models fooled\"].append(row[f'{label} difficulty score'])\n",
    "        \n",
    "to_df = pl.DataFrame(to_df).write_csv(input_file.replace('.csv', 'ADV_SAMPLES.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stats on the token lenghts between original and correct generated hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 12, 13, 10, 9, 10, 11, 5, 7, 7, 7, 7, 8, 6, 5, 4, 9, 13, 9, 7, 9, 5, 9, 14, 6, 6, 6, 10, 7]\n",
      "[32, 21, 21, 24, 21, 44, 25, 33, 48, 33, 22, 16, 22, 12, 23, 24, 24, 25, 23, 30, 30, 30, 29, 37, 24, 24, 28, 33, 33]\n",
      "> original hypotheses mean length: 8.21\n",
      "> generated hypotheses mean length: 27.28\t(3.32x)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "\n",
    "\n",
    "original_hypotheses_len = [] \n",
    "generated_hypotheses_len = [] \n",
    "\n",
    "for label in LABEL_NAMES:\n",
    "    samples = new_df.filter(\n",
    "        (pl.col(f'{label} Correct?') == True) & (pl.col(f'Generated {label} Hypothesis') != '')\n",
    "    )\n",
    "    for row in samples.iter_rows(named=True):\n",
    "        original_hypotheses_len.append(len(row['hypothesis'].strip().split(' ')))\n",
    "        generated_hypotheses_len.append(len(row[f'Generated {label} Hypothesis'].strip().split(' ')))\n",
    "print(original_hypotheses_len)\n",
    "print(generated_hypotheses_len)\n",
    "print(f\"> original hypotheses mean length: {mean(original_hypotheses_len):.2f}\")\n",
    "print(f\"> generated hypotheses mean length: {mean(generated_hypotheses_len):.2f}\\t({mean(generated_hypotheses_len)/mean(original_hypotheses_len):.2f}x original)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
