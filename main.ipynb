{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "This cell downloads and extracts the dataset from https://www.dropbox.com/s/hylbuaovqwo2zav/nli_fever.zip.\n",
    "- Execute it **ONLY ONCE**, at the start of your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-21 20:47:08--  https://www.dropbox.com/s/hylbuaovqwo2zav/nli_fever.zip\n",
      "Risoluzione di www.dropbox.com (www.dropbox.com)... 162.125.69.18, 2620:100:6025:18::a27d:4512\n",
      "Connessione a www.dropbox.com (www.dropbox.com)|162.125.69.18|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 302 Found\n",
      "Posizione: /s/raw/hylbuaovqwo2zav/nli_fever.zip [segue]\n",
      "--2024-05-21 20:47:08--  https://www.dropbox.com/s/raw/hylbuaovqwo2zav/nli_fever.zip\n",
      "Riutilizzo della connessione esistente a www.dropbox.com:443.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 302 Found\n",
      "Posizione: https://uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com/cd/0/inline/CTWbR5X3Yxt9XL98kIpkMW15vU9rxB5da0Z_1lYlyJL-I4Kc0CILXN4cbI6NH9z99T5dsxlGIyFUpkQQCG3RWMcCtyepPTK_2tsEH0pY_CK3vaqhMiDRjFuZAOy_B9yM1ipPvsyLl3Xo04fi20R-k1JK/file# [segue]\n",
      "--2024-05-21 20:47:09--  https://uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com/cd/0/inline/CTWbR5X3Yxt9XL98kIpkMW15vU9rxB5da0Z_1lYlyJL-I4Kc0CILXN4cbI6NH9z99T5dsxlGIyFUpkQQCG3RWMcCtyepPTK_2tsEH0pY_CK3vaqhMiDRjFuZAOy_B9yM1ipPvsyLl3Xo04fi20R-k1JK/file\n",
      "Risoluzione di uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com (uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com)... 162.125.69.15, 2620:100:6025:15::a27d:450f\n",
      "Connessione a uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com (uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com)|162.125.69.15|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 302 Found\n",
      "Posizione: /cd/0/inline2/CTUEFtomJStvSKA0j0lffGt7Ftc1Algov1nwRwBZihXvsE-YWfn_g1SW9lWXCKA5oKm7y1Lmi7u6uhaiVFMztLTUUFQNVgefCuYdeR2FTDf9CovXNUl8rm8EBQ9mOeebdY4O_LDDYdOt1ZFNvm8VFmmnE-i7M3dQEMGAZt40Pz4ZroBHmzfxMDTwyiydjv1iuJqFI9VNBHorgW0wUEmhG3dAo01cwZInImnS1ntD6_JdwmRUS-E-8E9b06kfEMSOQ1Y_LW80kMiapoVmNlqebRvfxPZ-bRO5MeQGnjlqwKBM106fqvj-gvgPRNmg9h_rx-e2yiSnMKwwY7QMXtkZrjU-pi9UXxZkYDPKwwGYQv6Z4HMBZgW7c9C9S5fp78SLeA0/file [segue]\n",
      "--2024-05-21 20:47:09--  https://uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com/cd/0/inline2/CTUEFtomJStvSKA0j0lffGt7Ftc1Algov1nwRwBZihXvsE-YWfn_g1SW9lWXCKA5oKm7y1Lmi7u6uhaiVFMztLTUUFQNVgefCuYdeR2FTDf9CovXNUl8rm8EBQ9mOeebdY4O_LDDYdOt1ZFNvm8VFmmnE-i7M3dQEMGAZt40Pz4ZroBHmzfxMDTwyiydjv1iuJqFI9VNBHorgW0wUEmhG3dAo01cwZInImnS1ntD6_JdwmRUS-E-8E9b06kfEMSOQ1Y_LW80kMiapoVmNlqebRvfxPZ-bRO5MeQGnjlqwKBM106fqvj-gvgPRNmg9h_rx-e2yiSnMKwwY7QMXtkZrjU-pi9UXxZkYDPKwwGYQv6Z4HMBZgW7c9C9S5fp78SLeA0/file\n",
      "Riutilizzo della connessione esistente a uc044a043b2fa4b989d886d12271.dl.dropboxusercontent.com:443.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 36923425 (35M) [application/zip]\n",
      "Salvataggio in: ‘nli_fever.zip’\n",
      "\n",
      "nli_fever.zip       100%[===================>]  35,21M  5,24MB/s    in 6,4s    \n",
      "\n",
      "2024-05-21 20:47:16 (5,49 MB/s) - ‘nli_fever.zip’ salvato [36923425/36923425]\n",
      "\n",
      "Archive:  nli_fever.zip\n",
      "   creating: nli_fever/\n",
      "  inflating: nli_fever/.DS_Store     \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/nli_fever/\n",
      "  inflating: __MACOSX/nli_fever/._.DS_Store  \n",
      "  inflating: nli_fever/train_fitems.jsonl  \n",
      "  inflating: __MACOSX/nli_fever/._train_fitems.jsonl  \n",
      "  inflating: nli_fever/dev_fitems.jsonl  \n",
      "  inflating: __MACOSX/nli_fever/._dev_fitems.jsonl  \n",
      "  inflating: nli_fever/README.md     \n",
      "  inflating: nli_fever/test_fitems.jsonl  \n",
      "  inflating: __MACOSX/nli_fever/._test_fitems.jsonl  \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/hylbuaovqwo2zav/nli_fever.zip\n",
    "!unzip \"nli_fever.zip\"\n",
    "!rm \"nli_fever.zip\"\n",
    "!rm -r \"__MACOSX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell initializes the models and the dataset.\n",
    "- You need to execute it **ONLY ONCE**, but, if for any reason the process crashes, you may try re-running from this cell (so you'll avoid downloading files again). \n",
    "- If it still crashes, then re-run from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208346 samples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "random.seed(3983751073717997123)\n",
    "\n",
    "LABEL_MAP = {\n",
    "    'SUPPORTS': 'entailment', \n",
    "    'NOT ENOUGH INFO': 'neutral', \n",
    "    'REFUTES': 'contradiction'\n",
    "}\n",
    "TRAIN_PATH = 'nli_fever/train_fitems.jsonl' \n",
    "with open(TRAIN_PATH, 'r') as fin:\n",
    "    dataset = []\n",
    "    for line in fin:\n",
    "        dataset.append(json.loads(line))\n",
    "\n",
    "to_sample = random.sample(population=range(0, len(dataset)), k=100)\n",
    "sampled = [dataset[i] for i in to_sample]\n",
    "#pprint(sampled)\n",
    "print(len(dataset), 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(claim:str):\n",
    "    return {'entailment' : random.random(), 'neutral' : random.random(), 'contradiction' : random.random()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Main Loop\n",
    "This cell contains the main part of the program: it will loop through each sample of the dataset, asking you to provide a new, hard to understand, hypothesis for each of them.\n",
    "\n",
    "You can choose either to:\n",
    "1. modify the given hypothesis, keeping the same label\n",
    "2. come up with a new hypothesis and its correspective label (you can also use ChatGPT for ideas)\n",
    "\n",
    "In both cases, when writing the result on [this google sheet](https://docs.google.com/spreadsheets/d/1k7JTOOS2jUDItxCh7xSjwf3eGR8skGP7P7HQGh7_WCg/edit#gid=0), write also the main \"change\" you performed.\n",
    "- You can come up with your categorization or take inspiration from the one of [this paper](https://arxiv.org/pdf/2010.12729) (see Table 2).\n",
    "\n",
    "NOTE: **The changes on the hypothesis can be anything as long as the label does not change**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition\n",
    "**Given**:\n",
    "- *M* :   ensemble of models that you will fool\n",
    "- *P* :   premise (the 'context')\n",
    "- *H* :   hypothesis (the 'claim'), simple enough so that *M* correctly classifies the relationship between *P* and *H*\n",
    "- *L* :   gold label (the relationship between *P* and *H*)\n",
    "\n",
    "**Task**: generate *H'* such that:\n",
    "1. *H* and *H'* have more or less the same meaning --> the relationship between *P* and *H'* is the same as the relationship between *P* and *H*\n",
    "2. *H'* can fool *M* --> *M* will predict a different relationship type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "[ID 48 - CID 79261]\n",
      "PREMISE:\n",
      "\t> Furious 7.\n",
      "\t> Principal photography began in Atlanta , Georgia , in September 2013 , resumed in April 2014 and ended in July 2014 , with other filming locations including Los Angeles , Colorado , Abu Dhabi , and Tokyo.\n",
      "\t> Furious 7 premiered in Los Angeles on April 1 , 2015 , and was theatrically released in the United States on April 3 , 2015 , playing in 3D , IMAX 3D , and 4DX internationally.\n",
      "HYPOTHESIS:\n",
      "\t> Furious 7 never concluded filming.\n",
      "GOLD LABEL: contradiction\n",
      "------------------------------\n",
      "PREDICTED LABEL **CHANGED**: >>>> neutral <<<< -- {'entailment': 53, 'neutral': 94, 'contradiction': 0}\n",
      "------------------------------\n",
      "[ID 49 - CID 210596]\n",
      "PREMISE:\n",
      "\t> Primal Fear is a 1996 American neo-noir crime-thriller film , based on William Diehl 's 1993 novel of the same name and directed by Gregory Hoblit.\n",
      "\t> Richard Gere.\n",
      "\t> He went on to star in several hit films , including An Officer and a Gentleman , Pretty Woman , Primal Fear , Runaway Bride , Arbitrage and Chicago , for which he won a Golden Globe Award for Best Actor and a Screen Actors Guild Award for part of the Best Cast.\n",
      "HYPOTHESIS:\n",
      "\t> Richard Gere starred in a neo-noir film.\n",
      "GOLD LABEL: entailment\n",
      "------------------------------\n",
      "PREDICTED LABEL: entailment -- {'entailment': 81, 'neutral': 49, 'contradiction': 32}\n"
     ]
    }
   ],
   "source": [
    "last = int(input(\"If you are resuming, enter the last ID you worked on (otherwise 0): \"))\n",
    "assert last < len(dataset), f\"You entered an ID value that is higher than the size of the dataset -- Rerun this cell.\"\n",
    "\n",
    "i = max(0, last) \n",
    "for elem in sampled[last:]:\n",
    "    print(\"-\"*30)\n",
    "    print(f\"[ID {i} - CID {elem['cid']}]\")\n",
    "    print(f\"PREMISE:\")\n",
    "    for context in elem['context'].split('.'):\n",
    "        if context.strip() != '':\n",
    "            print(f\"\\t> {context.strip()}.\")\n",
    "    print(f\"HYPOTHESIS:\\n\\t> {elem['query']}\")\n",
    "    print(f\"GOLD LABEL: {LABEL_MAP[elem['label']]}\")\n",
    "    print(\"-\"*30)\n",
    "\n",
    "    hypothesis = input(\"> type new hypothesis: \")\n",
    "    while hypothesis.lower() != 'n':\n",
    "        prediction = get_prediction(hypothesis)\n",
    "        # rescore for better visibility\n",
    "        prediction = {k: int(v*100) for k, v in prediction.items()}\n",
    "        predicted = max(prediction, key=prediction.get)\n",
    "        if predicted != LABEL_MAP[elem[\"label\"]]:\n",
    "            print(f\"PREDICTED LABEL **CHANGED**: >>>> {predicted} <<<< -- {prediction}\", flush=True)\n",
    "        else:\n",
    "            print(f\"PREDICTED LABEL: {predicted} -- {prediction}\", flush=True)\n",
    "        hypothesis = input(\"type n to exit, otherwise type new hyphotesis: \")\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV creation for step 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv written.\n",
      "shape: (3, 2)\n",
      "┌───────────────┬─────┐\n",
      "│ label         ┆ len │\n",
      "│ ---           ┆ --- │\n",
      "│ str           ┆ u32 │\n",
      "╞═══════════════╪═════╡\n",
      "│ entailment    ┆ 56  │\n",
      "│ neutral       ┆ 17  │\n",
      "│ contradiction ┆ 27  │\n",
      "└───────────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "to_csv = {\n",
    "    'id' : [],\n",
    "    'cid' : [], \n",
    "    'premise': [],\n",
    "    'hypothesis' : [],\n",
    "    'alternative hypothesis' : [], \n",
    "    'label' : [],\t\n",
    "    'new hypothesis': [], \t\n",
    "    'new label': [], \n",
    "    'change type':[]\n",
    "}\n",
    "for i, sample in enumerate(sampled):\n",
    "    to_csv['id'].append(i)\n",
    "    to_csv['cid'].append(sample['cid'])\n",
    "    to_csv['premise'].append(sample['context'])\n",
    "    to_csv['hypothesis'].append(sample['query'])\n",
    "    to_csv['alternative hypothesis'].append('')\n",
    "    to_csv['label'].append(LABEL_MAP[sample['label']])\n",
    "    to_csv['new hypothesis'].append('')\n",
    "    to_csv['new label'].append('')\n",
    "    to_csv['change type'].append('')\n",
    "to_csv = pl.from_dict(to_csv)\n",
    "to_csv.write_csv(TRAIN_PATH.replace('.jsonl', '.csv'), separator=',')\n",
    "print(\"csv written.\")\n",
    "\n",
    "q = (\n",
    "    to_csv.lazy()\n",
    "    .group_by(\"label\")\n",
    "    .len()\n",
    ")\n",
    "df = q.collect()\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
